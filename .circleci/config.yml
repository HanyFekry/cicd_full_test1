version: 2.1

defaults: &defaults
  docker:
    - image: cimg/base:2022.06
  working_directory: ~/project

jobs:
  build:
    working_directory: ~/project
    # Reuse Docker container specification given by the node Orb
    docker:
      # The primary container is an instance of the first image listed. The job's commands run in this container.
      - image: cimg/base:stable
    steps:
      - checkout
      - run:
          name: print hellow
          command: echo "hellow"

  test:
    docker:
      # The primary container is an instance of the first image listed. The job's commands run in this container.
      - image: cimg/base:stable
    steps:
      - checkout
      - run: echo "this is test"

  create_infrastructure: 
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file template.yml \
            --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
            --region us-west-2
      - run:
          name: rollback stack
          command:  |
            aws cloudformation delete-stack |
            --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
            --region us-west-2
          when:
            on_fail

  configure_infrastructure: 
    docker:
      - image: python:3.10.5-alpine3.15
    steps:
      - checkout
      - add_ssh_keys: 
          fingerprints: ["3c:f4:1e:07:f1:e8:1e:0f:bd:e3:55:cd:b4:54:8b:1c"]
#          fingerprints:["ac:30:0f:f3:3e:f5:64:a4:51:9b:93:e2:fd:fb:25:50"]
#      install ansible on ubuntu
      - run:
          name: install dependencies on ubuntu
          command: |
            apk add --update ansible
      - run: 
          name: play playbook
          command: |
            ansible-playbook -i inventory.txt playbook.yml

  smoke_test:
    docker:
      - image: alpine:latest
    environment:
      URL: "https://google.com"
    steps:
      - run: apk add --update curl
      - run:
          name: smoke test
          command: | 
            if curl -s --head ${URL} 
            then 
              return 0 
            else 
              return 1 
            fi
# Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
# Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
  # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync ./index.html s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

# Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt 

# Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
# Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

# Destroy the previous production version's S3 bucket and CloudFormation stack. 
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive

  test_onfail_job:
    <<: *defaults
    steps: 
      - run: exit 1 # exit code must be 0 to succeed
      - run: 
          name: do something when job fails
          command: echo this is a faild job
          when: on_fail
      # this step will not be excuted
      - run:
          name: test after fail
          command: echo this is after fail step
workflows:
  # test_ansible_jobs:
  #   jobs:
  #     - test_onfail_job

  # build_and_test:
    # jobs:
    #   - build
    #   - test:
    #       requires:
    #         - build
  # infra:
  #   jobs:
#      - create_infrastructure
#      - configure_infrastructure
  # smoke_test_jobs:
  #   jobs:
  #     - smoke_test

  my_workflow:
    jobs:
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production           